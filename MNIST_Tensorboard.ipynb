{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOGDIR = \"mnist_demo/\"\n",
    "LABELS = os.path.join(os.getcwd(), \"labels_1024.tsv\")\n",
    "SPRITES = os.path.join(os.getcwd(), \"sprite_1024.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/luis/media/Libros,Ebooks,Manuales,Tutoriales,Lecturas/udacity/deep-learning-nanodegree/projects/tensorboard/sprite_1024.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPRITES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_hparam_string(learning_rate, conv1_depth,conv2_depth,fc1_size,fc2_size):\n",
    "\n",
    "  return \"lr_\"+str(learning_rate)+\",conv1depth_\"+str(conv1_depth)+\",conv2depth_\"+str(conv2_depth)+\",fc1size_\"+str(fc1_size)+\",fc2size_\"+str(fc2_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lr_1,conv1depth_2,conv2depth_3,fc1size_4,fc2size_5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_hparam_string(1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input,channels_in,channels_out,name =\"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([5,5,channels_in,channels_out] ,stddev=0.1),name =\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1,shape= [channels_out]),name =\"B\")\n",
    "        conv = tf.nn.conv2d(input,w,strides = [1,1,1,1],padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv+b)\n",
    "        tf.summary.histogram(\"weights\",w)\n",
    "        tf.summary.histogram(\"biases\",b)\n",
    "        tf.summary.histogram(\"activations\",act)\n",
    "\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_layer(input,channels_in,channels_out,name =\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([channels_in,channels_out],stddev=0.1),name =\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1,shape=[channels_out]),name=\"B\")\n",
    "        act = tf.nn.relu(tf.matmul(input,w) + b)\n",
    "\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_mnist(learning_rate, conv1_depth,conv2_depth,fc1_size,fc2_size):\n",
    "    tf.reset_default_graph()\n",
    "    param_string  = make_hparam_string(learning_rate,conv1_depth,conv2_depth,fc1_size,fc2_size)\n",
    "    print(\"Starting training for:\"+param_string)\n",
    "    \n",
    "    x = tf.placeholder(tf.float32,shape=[None,784],name=\"x\")\n",
    "    y = tf.placeholder(tf.float32,shape=[None,10],name=\"labels\")\n",
    "    x_image = tf.reshape(x,[-1,28,28,1])\n",
    "    tf.summary.image('input',x_image,3)\n",
    "\n",
    "    conv1 = conv_layer(x_image,1,conv1_depth,\"conv1\")\n",
    "    pool1 = tf.nn.max_pool(conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "    conv2 = conv_layer(pool1,conv1_depth,conv2_depth,\"conv2\")\n",
    "    pool2 = tf.nn.max_pool(conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    flattened = tf.reshape(pool2,[-1,7*7*conv2_depth])\n",
    "\n",
    "    fc1 = fc_layer(flattened,7*7*conv2_depth,fc1_size,\"fc1\")\n",
    "    logits = fc_layer(fc1,fc1_size,fc2_size,\"fc2\")\n",
    "\n",
    "    with tf.name_scope(\"cross_entropy\"):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "        tf.summary.scalar('cross_entropy',cross_entropy)\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\",accuracy)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        merged_summary =  tf.summary.merge_all()\n",
    "        #the size of this tensor will be:n,d where n = size of data points to be displayed, d = embedding dimension, in this example n = size of test images passed\n",
    "        embedding = tf.Variable(tf.zeros([1024,fc1_size]),name =\"test_embedding\") \n",
    "        assigment = embedding.assign(fc1)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        writer = tf.summary.FileWriter(LOGDIR+param_string)\n",
    "        writer.add_graph(sess.graph)\n",
    "        \n",
    "\n",
    "        config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "        embedding_config = config.embeddings.add()\n",
    "        embedding_config.tensor_name = embedding.name\n",
    "        embedding_config.sprite.image_path = SPRITES\n",
    "        embedding_config.metadata_path = LABELS\n",
    "        \n",
    "        embedding_config.sprite.single_image_dim.extend([28,28])\n",
    "        tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer,config)\n",
    "        \n",
    "        for i in range(2001):\n",
    "            batch = mnist.train.next_batch(100)\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                [train_accuracy] = sess.run([accuracy],feed_dict =  {x:batch[0] , y:batch[1]})\n",
    "                summary = sess.run(merged_summary , feed_dict={x:batch[0],y:batch[1]})\n",
    "                sess.run(assigment,feed_dict={x:mnist.test.images[:1024],y:mnist.test.labels[:1024]})\n",
    "                if i%500 == 0:\n",
    "                    print(\"step %d ,training accuracy %g\" % (i,train_accuracy))\n",
    "                writer.add_summary(summary,i)\n",
    "                saver.save(sess,os.path.join(LOGDIR+param_string,\"model.ckpt\"),i)\n",
    "\n",
    "            sess.run(train_step,feed_dict = {x:batch[0],y:batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1E-3,1E-4,1E-5]\n",
    "conv1_depths = [16,32,64]\n",
    "conv2_depths = [32,64,128]\n",
    "fc1_sizes = [512,1024,2048]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_mnist(learning_rates[0],32,64,1024,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for:lr_0.001,conv1depth_16,conv2depth_32,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.07\n",
      "step 500 ,training accuracy 0.42\n",
      "step 1000 ,training accuracy 0.3\n",
      "step 1500 ,training accuracy 0.42\n",
      "step 2000 ,training accuracy 0.43\n",
      "Starting training for:lr_0.001,conv1depth_16,conv2depth_32,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.13\n",
      "step 500 ,training accuracy 0.12\n",
      "step 1000 ,training accuracy 0.13\n",
      "step 1500 ,training accuracy 0.07\n",
      "step 2000 ,training accuracy 0.12\n",
      "Starting training for:lr_0.001,conv1depth_16,conv2depth_32,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.1\n",
      "step 500 ,training accuracy 0.09\n",
      "step 1000 ,training accuracy 0.12\n",
      "step 1500 ,training accuracy 0.14\n",
      "step 2000 ,training accuracy 0.13\n",
      "Starting training for:lr_0.001,conv1depth_16,conv2depth_64,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.12\n",
      "step 500 ,training accuracy 0.39\n",
      "step 1000 ,training accuracy 0.33\n",
      "step 1500 ,training accuracy 0.38\n",
      "step 2000 ,training accuracy 0.38\n",
      "Starting training for:lr_0.001,conv1depth_16,conv2depth_64,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.13\n",
      "step 500 ,training accuracy 0.15\n",
      "step 1000 ,training accuracy 0.1\n",
      "step 1500 ,training accuracy 0.11\n",
      "step 2000 ,training accuracy 0.07\n",
      "Starting training for:lr_0.001,conv1depth_16,conv2depth_64,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.07\n",
      "step 500 ,training accuracy 0.1\n",
      "step 1000 ,training accuracy 0.13\n",
      "step 1500 ,training accuracy 0.04\n",
      "step 2000 ,training accuracy 0.16\n",
      "Starting training for:lr_0.001,conv1depth_16,conv2depth_128,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.09\n",
      "step 500 ,training accuracy 0.18\n",
      "step 1000 ,training accuracy 0.23\n",
      "step 1500 ,training accuracy 0.17\n",
      "step 2000 ,training accuracy 0.18\n",
      "Starting training for:lr_0.001,conv1depth_16,conv2depth_128,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.05\n",
      "step 500 ,training accuracy 0.1\n",
      "step 1000 ,training accuracy 0.13\n",
      "step 1500 ,training accuracy 0.12\n",
      "step 2000 ,training accuracy 0.13\n",
      "Starting training for:lr_0.001,conv1depth_16,conv2depth_128,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.11\n",
      "step 500 ,training accuracy 0.09\n",
      "step 1000 ,training accuracy 0.11\n",
      "step 1500 ,training accuracy 0.11\n",
      "step 2000 ,training accuracy 0.16\n",
      "Starting training for:lr_0.001,conv1depth_32,conv2depth_32,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.14\n",
      "step 500 ,training accuracy 0.19\n",
      "step 1000 ,training accuracy 0.35\n",
      "step 1500 ,training accuracy 0.37\n",
      "step 2000 ,training accuracy 0.54\n",
      "Starting training for:lr_0.001,conv1depth_32,conv2depth_32,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.09\n",
      "step 500 ,training accuracy 0.19\n",
      "step 1000 ,training accuracy 0.23\n",
      "step 1500 ,training accuracy 0.2\n",
      "step 2000 ,training accuracy 0.14\n",
      "Starting training for:lr_0.001,conv1depth_32,conv2depth_32,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.07\n",
      "step 500 ,training accuracy 0.75\n",
      "step 1000 ,training accuracy 0.65\n",
      "step 1500 ,training accuracy 0.71\n",
      "step 2000 ,training accuracy 0.71\n",
      "Starting training for:lr_0.001,conv1depth_32,conv2depth_64,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.1\n",
      "step 500 ,training accuracy 0.1\n",
      "step 1000 ,training accuracy 0.09\n",
      "step 1500 ,training accuracy 0.13\n",
      "step 2000 ,training accuracy 0.13\n",
      "Starting training for:lr_0.001,conv1depth_32,conv2depth_64,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.1\n",
      "step 500 ,training accuracy 0.08\n",
      "step 1000 ,training accuracy 0.12\n",
      "step 1500 ,training accuracy 0.15\n",
      "step 2000 ,training accuracy 0.13\n",
      "Starting training for:lr_0.001,conv1depth_32,conv2depth_64,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.05\n",
      "step 500 ,training accuracy 0.12\n",
      "step 1000 ,training accuracy 0.11\n",
      "step 1500 ,training accuracy 0.14\n",
      "step 2000 ,training accuracy 0.06\n",
      "Starting training for:lr_0.001,conv1depth_32,conv2depth_128,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.1\n",
      "step 500 ,training accuracy 0.07\n",
      "step 1000 ,training accuracy 0.07\n",
      "step 1500 ,training accuracy 0.14\n",
      "step 2000 ,training accuracy 0.1\n",
      "Starting training for:lr_0.001,conv1depth_32,conv2depth_128,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.09\n",
      "step 500 ,training accuracy 0.1\n",
      "step 1000 ,training accuracy 0.13\n",
      "step 1500 ,training accuracy 0.12\n",
      "step 2000 ,training accuracy 0.09\n",
      "Starting training for:lr_0.001,conv1depth_32,conv2depth_128,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.04\n",
      "step 500 ,training accuracy 0.18\n",
      "step 1000 ,training accuracy 0.33\n",
      "step 1500 ,training accuracy 0.49\n",
      "step 2000 ,training accuracy 0.53\n",
      "Starting training for:lr_0.001,conv1depth_64,conv2depth_32,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.18\n",
      "step 500 ,training accuracy 0.48\n",
      "step 1000 ,training accuracy 0.41\n",
      "step 1500 ,training accuracy 0.55\n",
      "step 2000 ,training accuracy 0.44\n",
      "Starting training for:lr_0.001,conv1depth_64,conv2depth_32,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.08\n",
      "step 500 ,training accuracy 0.07\n",
      "step 1000 ,training accuracy 0.06\n",
      "step 1500 ,training accuracy 0.15\n",
      "step 2000 ,training accuracy 0.09\n",
      "Starting training for:lr_0.001,conv1depth_64,conv2depth_32,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.1\n",
      "step 500 ,training accuracy 0.06\n",
      "step 1000 ,training accuracy 0.04\n",
      "step 1500 ,training accuracy 0.13\n",
      "step 2000 ,training accuracy 0.11\n",
      "Starting training for:lr_0.001,conv1depth_64,conv2depth_64,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.09\n",
      "step 500 ,training accuracy 0.2\n",
      "step 1000 ,training accuracy 0.27\n",
      "step 1500 ,training accuracy 0.26\n",
      "step 2000 ,training accuracy 0.16\n",
      "Starting training for:lr_0.001,conv1depth_64,conv2depth_64,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.08\n",
      "step 500 ,training accuracy 0.1\n",
      "step 1000 ,training accuracy 0.06\n",
      "step 1500 ,training accuracy 0.09\n",
      "step 2000 ,training accuracy 0.09\n",
      "Starting training for:lr_0.001,conv1depth_64,conv2depth_64,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.11\n",
      "step 500 ,training accuracy 0.48\n",
      "step 1000 ,training accuracy 0.44\n",
      "step 1500 ,training accuracy 0.49\n",
      "step 2000 ,training accuracy 0.5\n",
      "Starting training for:lr_0.001,conv1depth_64,conv2depth_128,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.09\n",
      "step 500 ,training accuracy 0.1\n",
      "step 1000 ,training accuracy 0.15\n",
      "step 1500 ,training accuracy 0.09\n",
      "step 2000 ,training accuracy 0.08\n",
      "Starting training for:lr_0.001,conv1depth_64,conv2depth_128,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.13\n",
      "step 500 ,training accuracy 0.11\n",
      "step 1000 ,training accuracy 0.13\n",
      "step 1500 ,training accuracy 0.13\n",
      "step 2000 ,training accuracy 0.15\n",
      "Starting training for:lr_0.001,conv1depth_64,conv2depth_128,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.11\n",
      "step 500 ,training accuracy 0.05\n",
      "step 1000 ,training accuracy 0.1\n",
      "step 1500 ,training accuracy 0.11\n",
      "step 2000 ,training accuracy 0.06\n",
      "Starting training for:lr_0.0001,conv1depth_16,conv2depth_32,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.08\n",
      "step 500 ,training accuracy 0.67\n",
      "step 1000 ,training accuracy 0.75\n",
      "step 1500 ,training accuracy 0.9\n",
      "step 2000 ,training accuracy 0.88\n",
      "Starting training for:lr_0.0001,conv1depth_16,conv2depth_32,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.12\n",
      "step 500 ,training accuracy 0.75\n",
      "step 1000 ,training accuracy 0.74\n",
      "step 1500 ,training accuracy 0.85\n",
      "step 2000 ,training accuracy 0.72\n",
      "Starting training for:lr_0.0001,conv1depth_16,conv2depth_32,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.08\n",
      "step 500 ,training accuracy 0.42\n",
      "step 1000 ,training accuracy 0.38\n",
      "step 1500 ,training accuracy 0.56\n",
      "step 2000 ,training accuracy 0.46\n",
      "Starting training for:lr_0.0001,conv1depth_16,conv2depth_64,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.17\n",
      "step 500 ,training accuracy 0.2\n",
      "step 1000 ,training accuracy 0.17\n",
      "step 1500 ,training accuracy 0.33\n",
      "step 2000 ,training accuracy 0.35\n",
      "Starting training for:lr_0.0001,conv1depth_16,conv2depth_64,fc1size_1024,fc2size_10\n",
      "step 0 ,training accuracy 0.09\n",
      "step 500 ,training accuracy 0.59\n",
      "step 1000 ,training accuracy 0.61\n",
      "step 1500 ,training accuracy 0.64\n",
      "step 2000 ,training accuracy 0.53\n",
      "Starting training for:lr_0.0001,conv1depth_16,conv2depth_64,fc1size_2048,fc2size_10\n",
      "step 0 ,training accuracy 0.09\n",
      "step 500 ,training accuracy 0.71\n",
      "step 1000 ,training accuracy 0.77\n",
      "step 1500 ,training accuracy 0.8\n",
      "step 2000 ,training accuracy 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for:lr_0.0001,conv1depth_16,conv2depth_128,fc1size_512,fc2size_10\n",
      "step 0 ,training accuracy 0.1\n",
      "step 500 ,training accuracy 0.05\n",
      "step 1000 ,training accuracy 0.13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7c6885566fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv2_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconv2_depths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfc1_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfc1_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 \u001b[0mtrain_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv1_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv2_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfc1_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-0d0c274a688f>\u001b[0m in \u001b[0;36mtrain_mnist\u001b[0;34m(learning_rate, conv1_depth, conv2_depth, fc1_size, fc2_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOGDIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mparam_string\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/luis/anaconda2/envs/dlnd_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda2/envs/dlnd_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda2/envs/dlnd_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/luis/anaconda2/envs/dlnd_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda2/envs/dlnd_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for learning_rate in learning_rates:\n",
    "    for conv1_depth in conv1_depths:\n",
    "        for conv2_depth in conv2_depths:\n",
    "            for fc1_size in fc1_sizes:\n",
    "                train_mnist(learning_rate,conv1_depth,conv2_depth,fc1_size,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch tensorboard passing --logdir <path used in FileWriter> :\n",
    "tensorboard --logdir /tmp/mnist_demo/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* To use tensorboard, you create a tf.summary.FileWriter(\"logs path\") which is used later to write to a log your graph,scalars,histograms,images, audio or other information.\n",
    "* To write the network's graph to the logs, use(assuming tensorflow session is called sess): \n",
    "        writer = tf.summary.FileWriter(\"log dir\")\n",
    "        writer.add_graph(sess.graph)\n",
    "* The default generated graph its very complex and provides low level details, to get a cleaner and simplear graph, we need to group operations together, this is done using name scopes, a group of related operations is assigned a name scope using tf.name_scope,  for example for a fully conected layer, we would group operations like:\n",
    "        with tf.name_scope(name):\n",
    "            w = tf.Variable(tf.truncated_normal([channels_in,channels_out],stddev=0.1),name =\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1,shape=[channels_out]),name=\"B\")\n",
    "            act = tf.nn.relu(tf.matmul(input,w) + b)\n",
    "* Tensorboard can show other data and how it evolves in training(for example cost in time) using distinct types of summaries, you just create new summaries,for every summary pass a name, and a tensorflow node that you want to display. The types of summaries are:\n",
    "    * Scalars: for scalar numbers like cost,accuracy,or other performance metrics(precision,recall,right predictions,wrong predictions, etc) we use Scalars , for example if you have a tensorflow node called cost  you will use:\n",
    "            cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "            tf.summary.scalar('cross_entropy',cross_entropy)\n",
    "      This will create a new chart in the \"Scalars\" tab of tensorboard\n",
    "    * Histograms: for multivalued variables, for example a weights matrix or vector, to see its distribution, we create a histogram summary , this creates a chart in the histograms tab, as well as the distributions tab,for example to get the histogram and distribution of a biases vector:\n",
    "             b = tf.Variable(tf.constant(0.1,shape= [channels_out]),name =\"B\")\n",
    "             tf.summary.histogram(\"biases\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
